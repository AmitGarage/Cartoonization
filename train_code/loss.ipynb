{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greatest-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "through-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_MEAN = [103.939, 116.779, 123.68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accredited-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg19beforefc :\n",
    "    def __init__(self, vgg19_pt_path=None):\n",
    "        self.cnn = models.vgg19(pretrained=False).eval()\n",
    "        self.previous_weights = torch.load(vgg19_pt_path)\n",
    "        #self.data_dict = np.load(vgg19_npy_path, encoding='latin1', allow_pickle=True).item()\n",
    "        #print('Finished loading vgg19.npy')\n",
    "        self.vgg19_model = self.vgg19_definition()\n",
    "    \n",
    "    def build_model(self , rgb, include_fc=False) :\n",
    "        \n",
    "        rgb_scaled = (rgb+1) * 127.5\n",
    "        \n",
    "        blue, green, red = torch.split(tensor=rgb_scaled,split_size_or_sections=3,dim=0)\n",
    "        bgr = torch.cat(tensors=(blue - VGG_MEAN[0],green - VGG_MEAN[1], red - VGG_MEAN[2]),dim=3)\n",
    "        \n",
    "        return self.vgg19_model(bgr)\n",
    "        \n",
    "    def vgg19_definition(self) :\n",
    "        cnn = copy.deepcopy(self.cnn)\n",
    "        # Initalize model and add layers in sequential order\n",
    "        model = nn.Sequential()\n",
    "        # Initalize layer number\n",
    "        conv_layer = 0\n",
    "        # Loop to add layer and layer name to model\n",
    "        for layer in cnn.children() :\n",
    "            if isinstance(layer ,nn.Conv2d) :\n",
    "                conv_layer += 1\n",
    "                layer_name = 'conv_{}'.format(conv_layer)\n",
    "            elif isinstance(layer ,nn.ReLU) :\n",
    "                layer_name = 'relu_{}'.format(conv_layer)\n",
    "                layer = nn.ReLU(inplace = False)\n",
    "            elif isinstance(layer ,nn.MaxPool2d) :\n",
    "                layer_name = 'maxPool_{}'.format(conv_layer)\n",
    "            elif isinstance(layer ,nn.BatchNorm2d) :\n",
    "                layer_name = 'batchNorm_{}'.format(conv_layer)\n",
    "            else :\n",
    "                raise RuntimeError('Unrecognized layer : {}'.format(layer.__class__.__name__))\n",
    "            \n",
    "            model.add_module(layer_name , layer)\n",
    "            #print(model)\n",
    "         \n",
    "            #print(conv_layer)\n",
    "        # Loop from reverse to count no of layer in model excluding any flatten layer\n",
    "        #for conv_layer in range(len(model)-1,-1,-1) :\n",
    "        #    if isinstance(model[conv_layer], PicContentLoss) or isinstance(model[conv_layer], PicStyleLoss) :\n",
    "        #        break\n",
    "    \n",
    "        #print(conv_layer)  \n",
    "        #print(model[conv_layer])\n",
    "        # Final model over which training will be done\n",
    "        #model = model[:(conv_layer+1)]\n",
    "        #print(model)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liable-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19loss(image_a,image_b) :\n",
    "    vgg_model = Vgg19('vgg19_no_fc.pt')\n",
    "    vgg_model_image_a = vgg_model.build_model(image_a)\n",
    "    vgg_model_image_b = vgg_model.build_model(image_b)\n",
    "    loss = torch.nn.L1Loss()\n",
    "    vgg_loss = loss(vgg_model_image_a-vgg_model_image_b)\n",
    "    h, w, c= vgg_a.get_shape().as_list()[1:]\n",
    "    vgg_loss = torch.mean(vgg_loss)/(h*w*c)\n",
    "        \n",
    "    return vgg_loss\n",
    "    \n",
    "def wgan_loss(discriminator, real, fake, patch=True, channel=32, lambda_=2) :\n",
    "    real_logits = discriminator(real, patch=patch, channel=channel)\n",
    "    fake_logits = discriminator(fake, patch=patch, channel=channel)\n",
    "\n",
    "    d_loss_real = - torch.mean(real_logits)\n",
    "    d_loss_fake = torch.mean(fake_logits)\n",
    "\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    g_loss = - d_loss_fake\n",
    "\n",
    "    \"\"\" Gradient Penalty \"\"\"\n",
    "    # This is borrowed from https://github.com/kodalinaveen3/DRAGAN/blob/master/DRAGAN.ipynb\n",
    "    alpha = torch.rand([real.shape[0], 1, 1, 1])\n",
    "    differences = fake - real # This is different from MAGAN\n",
    "    interpolates = real + (alpha * differences)\n",
    "    inter_logit = discriminator(interpolates, channel=channel)\n",
    "    inter_logit.backward(torch.ones(interpolates.shape))\n",
    "    gradients = interpolates.grad[0]\n",
    "    #gradients = tf.gradients(inter_logit, [interpolates])[0]\n",
    "    slopes = torch.sqrt(torch.sum(torch.square(gradients), axis=[1]))\n",
    "    gradient_penalty = torch.mean((slopes - 1.) ** 2)\n",
    "    d_loss += lambda_ * gradient_penalty\n",
    " \n",
    "    return d_loss, g_loss\n",
    "    \n",
    "def gan_loss(discriminator, real, fake, scale=1,channel=32, patch=False):\n",
    "    real_logit = discriminator(real, scale, channel, patch=patch)\n",
    "    fake_logit = discriminator(fake, scale, channel, patch=patch)\n",
    "\n",
    "    real_logit = torch.nn.Sigmoid(real_logit)\n",
    "    fake_logit = torch.nn.Sigmoid(fake_logit)\n",
    "    \n",
    "    g_loss_blur = -torch.mean(torch.log(fake_logit)) \n",
    "    d_loss_blur = -torch.mean(torch.log(real_logit) + torch.log(1. - fake_logit))\n",
    "\n",
    "    return d_loss_blur, g_loss_blur\n",
    "\n",
    "\n",
    "\n",
    "def lsgan_loss(discriminator, real, fake, scale=1, channel=32, patch=False):\n",
    "    real_logit = discriminator(real, scale, channel, patch=patch)\n",
    "    fake_logit = discriminator(fake, scale, channel, patch=patch)\n",
    "\n",
    "    g_loss = torch.mean((fake_logit - 1)**2)\n",
    "    d_loss = 0.5*(torch.mean((real_logit - 1)**2) + torch.mean(fake_logit**2))\n",
    "    \n",
    "    return d_loss, g_loss\n",
    "\n",
    "def total_variation_loss(image, k_size=1):\n",
    "    h, w = image.get_shape().as_list()[1:3]\n",
    "    tv_h = torch.mean((image[:, k_size:, :, :] - image[:, :h - k_size, :, :])**2)\n",
    "    tv_w = torch.mean((image[:, :, k_size:, :] - image[:, :, :w - k_size, :])**2)\n",
    "    tv_loss = (tv_h + tv_w)/(3*h*w)\n",
    "    return tv_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-trance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
