# White Box Cartoonization 
Converting real world images to cartoonized images using White Box Cartoonization algorithm

# Reference to original paper and code ( Tensorflow V1 ) by the creator
[CVPR2020]Learning to Cartoonize Using White-box Cartoon Representations
[project page](https://systemerrorwang.github.io/White-box-Cartoonization/) |   [paper](https://github.com/SystemErrorWang/White-box-Cartoonization/blob/master/paper/06791.pdf) |   [twitter](https://twitter.com/IlIIlIIIllIllII/status/1243108510423896065) |   [zhihu](https://zhuanlan.zhihu.com/p/117422157) |   [bilibili](https://www.bilibili.com/video/av56708333) |  [facial model](https://github.com/SystemErrorWang/FacialCartoonization)

Identify three white-box representations from images :-
- Surface representation - Contains a smooth surface of cartoon images. Extract a weighted low-frequency component, where the color composition and surface texture are preserved with edges, textures and details ignored. Motivated by the cartoon painting behavior where artists usually draw composition drafts before the details are retouched. In this work, we adapt a differentiable guided filter to extract smooth, cartoon-like surface from images, enabling our model to learn structure-level composition and smooth surface that artists have created in cartoon artworks. Lsurface(G, Ds) = logDs(Fdgf (Ic, Ic)) + log(1 âˆ’ Ds(Fdgf (G(Ip), G(Ip))))
- Structure representation - It refers to the sparse color-blocks and flatten global content in the celluloid style workflow. Extract a segmentation map from the input image and then apply an adaptive coloring algorithm on each segmented regions to generate the structure representation. Motivated to emulate the celluloid cartoon style, which is featured by clear boundaries and sparse color blocks. Super-pixel segmentation groups spatially connected pixels in an image with similar color or gray level. In this work, we follow the felzenszwalb algorithm to develop a cartoon-oriented segmentation method to achieve a learnable structure representation.
- Texture representation - It reflects highfrequency texture, contours, and details in cartoon images.  The input image is converted to a single-channel intensity map , where the color and luminance are removed and relative pixel intensity is preserved. Motivated by a cartoon painting method where artists firstly draw a line sketch with contours and details, and then apply color on it.

<br><br><br>

- In this paper, we adopt an unpaired image-to-image translation framework for image cartoonization. We decompose images into several representations, which enforces network to learn different features with separate objectives, making the learning process controllable and tunable.
- A GAN framework with a generator G and two discriminators Ds and Dt is proposed, where Ds aims to distinguish between surface representation extracted from model outputs and cartoons, and Dt is used to distinguish between texture representation extracted from outputs and cartoons.
- Pre-trained VGG network is used to extract high-level features and to impose spatial constrain on global contents between extracted structure representations and outputs, and also between input photos and outputs. Weight for each component can be adjusted in the loss function, which allows users to control the output style and adapt the model to diverse use cases.
